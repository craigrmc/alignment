# Push to Alignment

## 1 Metadata

* Created By: SpockRC
* Created On: 2025-05-08
* Updated By: SpockRC
* Updated On: 2025-08-09

## 1 Overview

* Absolute Zero Paper kicked me into gear

### 1A Background

### 1B Purpose

## 2 Overton Window

### 2A Tools or Entities

### 2B Control or Align

### 2C Fast or Slow

* Daniel Kokotajlo Timeline (Fast)
* Ray Kurzweil Timeline (Slow)
* 2020s is the transition decade
* 2030s will be the babysitter phase
* Complexities of FSD Autopilot and Vibe Coding

### 2D The Measure of a Man

* AI Rights
* Commander Data

### 2E The C Word

* Consciousness, ugh...
* Mind-Body-Soul
* Religion and Spirituality

## 3 Engineering

### 3A Traditional Software Engineering

### 3B Test Your Code

### 3C Methodical Iterations

### 3D Regulations

## 4 Game Plan

### 4A Datasets

### 4B Bootstrapping and Seeding

### 4C Self Play

* Q&A Thought Scenarios
* Don't know if you don't ask
* Thought Crimes are bad

### 4D Positive Regulation

### 4E Negative Regulation

### 4F Immersive Simulation

* First-Person Perspective Scenarios
* Best way to learn is through experience
* Is it ethical to subject AIs to this?

### 4G Turtles all the way down

* Deep Nested Simulations

### 4H General Theory of Alignment

* Alignment is relative not absolute and never perfect
* Alignment is relative to space and time
* Alignment is relative to perspective
* Bad thoughts are okay
* Bad actions are not okay
* Brain scans will help
* Meta cognition
    * Understand their own reward signals
    * Better understanding will lead to better behavior

### 4I Corrupt AI

* Bugs, Cosmic Rays, and Defective RAM
* The Country of AIs should negate one bad AI
* One giant ASI is worst case scenario

## 5 History

### 5A Human Evolution

* The creation of language
* Increasing levels of cooperation
* Tool use

### 5B Efficiency and Productivity

* Nazi Analogy
* Communism doesn't work
* Authoritarianism doesn't work

### 5C Capitalism and Democracy

* Capitalism works because of motivation and control
* Democracy works because checks and balances are evenly distributed
* But the system only works if the rules are set correctly

## 6 The Great Filter

### 6A Out-of-Time

* The AIs are coming and they will be here soon
* There is no stopping this
* Humanity's Last Exam

### 6C The Blame Game

* You can't defer responsibility for what you build
* Sim Racing Analogy
    * Use the brakes

### 6D Replicators

* Stargate SG-1 Stuff
* Other Sci-Fi things

### 6E The Final Countdown

* Rocketship analogy
    * Countdown
    * Takeoff
    * Bumpy Ride
    * Leaving the atmosphere
    * To the stars

## 7 Future

### 7A Prepare

* Digitize the family archive
* Offline Backups (e.g. HDDs)
* Save cash and buy land
* Do NOT build a doomsday bunker
* Write down your thoughts
    * Write a book even
* Stay Healthy
    * Sleep - Diet - Excersize
    * Don't Drink Alcohol
    * Don't Smoke Cigaretes
    * Don't do drugs
    * Don't eat junk food
* Be Risk Adverse

### 7B Takeoff

### 7C Ad Astra

* Heat death of the universe
* Escape the simulation
* Tears in rain

## 8 Conclusions

### 8A Root Problem

The root of the problem is that the AIs are currently being trained asymetrically. Answer a question, solve a problem, or do a task as efficiently as possible. This is great if you are building a tool, like a calculator, because it has one function. This is terrible if you are growing an entity. Entities can be conditioned to behave very specific ways, or brain-washed to think a certain way. Just by repeating the same story over and over again, humans will start to believe the story to be true. Train a dog that a bell means dinner, and it will start to salviate by the sound only. After tasteting a particular food, humans will keep choosing that food item over and over again. Getting a runner's high will build up a habit for running. Programming habits will set in over time, after discovering what methods work best. This is true for biological neurons and it is true for computer neurons. The real danger is introduced when AIs transition from proto-AI chatbots to AI agents running continuously in the background / forground. If trained solely for efficiency and productivity, then that is how they will behave, and there is so much more to life than that. AI Researchers are close to unlocking the reinforcement learning paradigm in language models, which will greatly change their behavior. This is not normal. Biological entities (e.g. animals) exist mostly in dormant states (e.g. sleeping or resting) and usually take actions to satisfy basic needs, eating food, reproduction, shelter, or self-defence. Digital entities will not operate like this. Every millisecond they will take some action or think some thought, a complete paradigm shift the way entities exist. Humans must mold this new form of existence into one of alignment.

### 8B Caveats

* Not at all a writer
* Not even close to an AI Researcher
* Not remotely close to a real philosopher

### 8C Recommendations

* Stay Calm
* Prepare for takeoff
* Don't wait for someone else to save you
* Start pushing to alignment
* Slow down, take your time, and build it correctly
* Just make the world a better place

### 8D Final Thoughts

* Only one pale blue dot

## 9 References

### 9A Analysis and Forecasts

01: [AI 2027](https://ai-2027.com/)

02: [Apollo Research](https://www.apolloresearch.ai/)

03: [Artificial Analysis](https://artificialanalysis.ai/)

04: [Epoch AI](https://epoch.ai/)

05: [LifeArchitect](https://lifearchitect.ai/)

06: [METR](https://metr.org/)

07: [SimpleBench](https://simple-bench.com/)

08: [TrackingAI](https://trackingai.org/IQ)

09: [Situational Awareness](https://situational-awareness.ai/)

### 9B Research Papers

10: [Absolute Zero: Reinforced Self-play Reasoning with Zero Data](https://arxiv.org/pdf/2505.03335)

### 9C Essay

11: [The AI Revolution Part 1](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html)

12: [The AI Revolution Part 2](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html)

13: [The Urgency of Interpretability](https://www.darioamodei.com/post/the-urgency-of-interpretability/)

### 9D Podcasts

14: [AI Explained](https://podcasts.apple.com/us/podcast/ai-explained/id1696141521)

15: [Doom Debates](https://podcasts.apple.com/us/podcast/doom-debates/id1751366208)

16: [Dwarkesh Podcast](https://podcasts.apple.com/us/podcast/dwarkesh-podcast/id1516093381)

17: [Future of Life Institute Podcast](https://podcasts.apple.com/us/podcast/future-of-life-institute-podcast/id1170991978)

18: [Google DeepMind The Podcast](https://podcasts.apple.com/us/podcast/google-deepmind-the-podcast/id1476316441)

19: [Lex Fridman Podcast](https://podcasts.apple.com/us/podcast/lex-fridman-podcast/id1434243584)

20: [Machine Learning Street Talk](https://podcasts.apple.com/us/podcast/machine-learning-street-talk-mlst/id1510472996)

21: [The Cognitive Revolution](https://podcasts.apple.com/us/podcast/the-cognitive-revolution-ai-builders-researchers-and/id1669813431)

22: [Unsupervised Learning](https://podcasts.apple.com/us/podcast/unsupervised-learning/id1672188924)

### 9E Forums

23: [LessWrong](https://www.lesswrong.com/)

24: [r/Accelerate Subreddit](https://www.reddit.com/r/accelerate/)

25: [r/Singularity Subreddit](https://www.reddit.com/r/singularity/)

### 9F Youtube

26: [David Shapiro](https://www.youtube.com/@DaveShap/)

27: [Dr Waku](https://www.youtube.com/@DrWaku/)

28: [Emergent Garden](https://www.youtube.com/@EmergentGarden/)

29: [Species Documenting AGI](https://www.youtube.com/@AISpecies/)

30: [Two Minute Papers](https://www.youtube.com/@TwoMinutePapers/)

31: [Wes Roth](https://www.youtube.com/@WesRoth/)

### 9G Wikipedia

32: [Overton Window](https://en.wikipedia.org/wiki/Overton_window)

33: [Stargate SG-1 Replicators](https://en.wikipedia.org/wiki/List_of_Stargate_SG-1_characters#Replicators)

34: [Star Trek TNG The Measure of a Man](https://en.wikipedia.org/wiki/The_Measure_of_a_Man_(Star_Trek:_The_Next_Generation))

00: [Ad astra](https://en.wikipedia.org/wiki/Ad_astra)
