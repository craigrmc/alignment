# Push to Alignment

## 1 Metadata

* Author: SpockRC
* Date: 2025-05-08

## 1 Overview

### 1.1 Background

### 1.1 Purpose

## 1 Overton Window

### 1.1 Tools or Entities

### 1.1 Control or Align

### 1.1 AI Rights

## 1 Game Plan

### 1.1 Datasets

### 1.1 Seeding

### 1.1 Bootstrapping

### 1.1 Self Play

### 1.1 Fast or Slow

### 1.1 Traditional Software Engineering

### 1.1 Positive Regulation

### 1.1 Negative Regulation

### 1.1 General Theory of Alignment

Alignment is relative not absolute and never perfect.

### 1.1 Immersive Simulation

### 1.1 Turtles all the way down

## 1 Traditional Software Engineering

### 1.1 Test Your Code

### 1.1 Iterate

## 1 History

### 1.1 Efficiency

### 1.1 Productivity

## 1 The Great Filter

### 1.1 Out-of-Time

### 1.1 The Final Countdown

### 1.1 The Blame Game

## 1 Future

### 1.1 Prepare

### 1.1 Takeoff

### 1.1 Ad Astra

## 1 Conclusions

### 1.1 Summary

### 1.1 Recommendations

### 1.1 Final Thoughts

## 1 References

### 1.1 Analysis and Forecasts

[^01]: [AI 2027](https://ai-2027.com/)

[^02]: [Apollo Research](https://www.apolloresearch.ai/)

[^03]: [Artificial Analysis](https://artificialanalysis.ai/)

[^04]: [Epoch AI](https://epoch.ai/)

[^05]: [LifeArchitect](https://lifearchitect.ai/)

[^06]: [METR](https://metr.org/)

[^07]: [SimpleBench](https://simple-bench.com/)

[^08]: [TrackingAI](https://trackingai.org/IQ)

### 1.1 Research Papers

[^09]: Absolute Zero: Reinforced Self-play Reasoning with Zero Data [Link](https://arxiv.org/pdf/2505.03335)

### 1.1 Essay

[^00]: [Dario](https://www.darioamodei.com/post/the-urgency-of-interpretability/)

### 1.1 Podcasts

[^10]: [AI Explained](https://podcasts.apple.com/us/podcast/ai-explained/id1696141521)

[^11]: [Doom Debates](https://podcasts.apple.com/us/podcast/doom-debates/id1751366208)

[^12]: [Dwarkesh Podcast](https://podcasts.apple.com/us/podcast/dwarkesh-podcast/id1516093381)

[^13]: [Future of Life Institute Podcast](https://podcasts.apple.com/us/podcast/future-of-life-institute-podcast/id1170991978)

[^14]: [Google DeepMind The Podcast](https://podcasts.apple.com/us/podcast/google-deepmind-the-podcast/id1476316441)

[^15]: [Lex Fridman Podcast](https://podcasts.apple.com/us/podcast/lex-fridman-podcast/id1434243584)

[^16]: [Machine Learning Street Talk](https://podcasts.apple.com/us/podcast/machine-learning-street-talk-mlst/id1510472996)

[^17]: [The Cognitive Revolution](https://podcasts.apple.com/us/podcast/the-cognitive-revolution-ai-builders-researchers-and/id1669813431)

[^18]: [Unsupervised Learning](https://podcasts.apple.com/us/podcast/unsupervised-learning/id1672188924)

### 1.1 Forums

[^19]: [LessWrong](https://www.lesswrong.com/)

[^20]: [r/Accelerate Subreddit](https://www.reddit.com/r/accelerate/)

[^21]: [r/Singularity Subreddit](https://www.reddit.com/r/singularity/)

### 1.1 Youtube

[^22]: [David Shapiro](https://www.youtube.com/@DaveShap/)

[^23]: [Dr Waku](https://www.youtube.com/@DrWaku/)

[^24]: [Emergent Garden](https://www.youtube.com/@EmergentGarden/)

[^25]: [Species Documenting AGI](https://www.youtube.com/@AISpecies/)

[^26]: [Two Minute Papers](https://www.youtube.com/@TwoMinutePapers/)

[^27]: [Wes Roth](https://www.youtube.com/@WesRoth/)
