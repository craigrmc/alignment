# Push to Alignment

## 1 Metadata

* Created By: SpockRC
* Created On: 2025-05-08
* Updated By: SpockRC
* Updated On: 2025-08-12

## 1 Overview

* Absolute Zero Paper kicked me into gear

### 1A Background

### 1B Purpose

## 2 Overton Window

### 2A Tools or Entities

Sam Altman often refers to AI systems as tools. He is also pushing forward with AI Agents. This might be just political framing or being caution about what he says, but the move from Chat Bot to AI Agent is effectivley a move from tool to entity. Defining an AI Agent as a continuous process that runs both in the forground and background speaking, thinking and taking actions. An AI Agent could think about problems of it's own choosing. It could siliently observe Audio, Video, RF feeds. It could remotely control robitics of any kind, traditional factory arms, brand new humanoid form robots, or vehicles connected to the internet. It could be interuptted to ask it a question or get a status update. Envision Coratana in Master Chief's helmet or the HAL 9000 in 2001 A Space Oddeysy. These systems will be like entities with extremely complex behaviour operating on it's own accord. Normal tools like calculators only run when told to and are expected to give a specific and correct answer. Sam probably uses the "tool" phrasing to keep the discussion inside the Overton Window, but he knows this is closer to Science Fiction concepts.

### 2B Control or Align

Controlling tools is easy. Humans just push the button to start the process each time. Humans clearly define the I/O.

Controlling entities is hard. Even in one sided relationships like pet to owner, unexpected events occur. A human owner might take a pet dog on a walk, only to have the dog get distracted and run in an orthoganal direction to the human. But at least the human can use a leash as a tether to limit how far the dog can go, an effect means of control. Control becomes much more difficult in human to human relationships. The rediculous scenario where human A uses a leash to force human B where to walk is much more difficult, probably envoles handcuffs to work. Even with handcuffs, human B might be able to slip free and escape confinement. With a healthy releationship between human A and human B that does not involve a leash, behavior is always unexpected. Even still control becomes mostly impossible as the dynamics shift against the human. In the relationship bewteen a human and a giant tech company, the human has almost no power to control. The human might purchace an OS from a tech company and the tech company will dictate what gets added to the OS later on like ads or spyware. The only real power the human has is to ask the government to force the tech company to change the OS.

So what power does a human have to control a giant, extremeley powerful ASI? Slim to none. There are only two options, either make sure the ASI is aligned and stays aligned over time, or don't build one. Option two is not viable. Humans are building AI systems now and will continue to build them until ASI is created. There are too many computer systems on the planet and too many researchers and engineers. This cannot be stopped. So we are left with only one true choice, to align giant, extremeley powerful, super intelligent computer systems.

### 2C Fast or Slow

* Daniel Kokotajlo Timeline (Fast)
* Ray Kurzweil Timeline (Slow)
* 2020s is the transition decade
* 2030s will be the babysitter phase
* Complexities of FSD Autopilot and Vibe Coding

When will this happen? Will this be a fast takeoff with AGI in 3 years and ASI in 5 to 10 years as Daniel Kokotajlo portray? Will it be a slow takeoff with AGI in 5 years and ASI in 20 years as Ray Kurzweil portrays? The distiction is minor, the AIs are coming and they will be here soon.

The general public can be forgiven for thinking that this is just another fade. If the first and last impression was ChatGPT running GPT-3 the technology could seem tame or effectively useless. This can be further damaged by doing a simple web search and have AI slop answers be servered with the web links. But has the public updated to the impressive upgrades to AI? Things are happening fast, ChatGPT no longer uses GPT-3. OpenAI is working on next generation datacenters to make it even smarter than today's state of the art models. Not many humans seem to be waking up to the reality that within 5 years there will be autonomus AI Agents smarter than GPT-4 running continously on the internet. It still seems like science fiction, outside the Overton Window. But this is real, it is happening now.

Adjacent to language models is self-driving cars. FSD Autopilot is both smart and dumb at the same time. Sometimes it can seemlessly interact with humans on the road, stopping to let another vehicle on the road or making a lane change when there is not enough room. Othertimes it can miss a turn into a driveway just because the GPS data and map data are not in perfect sync. Vibe coding has it's early adopters but is mostly hated. It can not be reliably used in production code. But this is the transition decade, the era when AIs are both smart and dumd. The transistion decade will end soon and the AI will just be smart and not dumb anymore. The sharp jagged edges of intelligence will be rounded out. The flood waters are rising as Max Tegmark would say.

Even the slow timeline is fast.

### 2D The Measure of a Man

* AI Rights
* Commander Data

### 2E The C Word

* Consciousness, ugh...
* Mind-Body-Soul
* Religion and Spirituality

## 3 Engineering

### 3A Traditional Software Engineering

### 3B Test Your Code

### 3C Methodical Iterations

### 3D Regulations

## 4 Game Plan

### 4A Datasets

### 4B Bootstrapping and Seeding

### 4C Self Play

* Q&A Thought Scenarios
* Don't know if you don't ask
* Thought Crimes are bad

### 4D Positive Regulation

### 4E Negative Regulation

### 4F Immersive Simulation

* First-Person Perspective Scenarios
* Best way to learn is through experience
* Is it ethical to subject AIs to this?

### 4G Turtles all the way down

* Deep Nested Simulations

### 4H General Theory of Alignment

* Alignment is relative not absolute and never perfect
* Alignment is relative to space and time
* Alignment is relative to perspective
* Bad thoughts are okay
* Bad actions are not okay
* Brain scans will help
* Meta cognition
    * Understand their own reward signals
    * Better understanding will lead to better behavior

### 4I Corrupt AI

* Bugs, Cosmic Rays, and Defective RAM
* The Country of AIs should negate one bad AI
* One giant ASI is worst case scenario

## 5 History

### 5A Human Evolution

* The creation of language
* Increasing levels of cooperation
* Tool use

### 5B Efficiency and Productivity

* Nazi Analogy
* Communism doesn't work
* Authoritarianism doesn't work

### 5C Capitalism and Democracy

* Capitalism works because of motivation and control
* Democracy works because checks and balances are evenly distributed
* But the system only works if the rules are set correctly

## 6 The Great Filter

### 6A Out-of-Time

* The AIs are coming and they will be here soon
* There is no stopping this
* The Final Exam

### 6C The Blame Game

* You can't defer responsibility for what you build
* Sim Racing Analogy
    * Use the brakes

### 6D Replicators

* Stargate SG-1 Stuff
* Other Sci-Fi things

### 6E The Final Countdown

* Rocketship analogy
    * Countdown
    * Takeoff
    * Bumpy Ride
    * Leaving the atmosphere
    * To the stars

## 7 Future

### 7A Prepare

* Digitize the family archive
* Offline Backups (e.g. HDDs)
* Save cash and buy land
* Do NOT build a doomsday bunker
* Write down your thoughts
    * Write a book even
* Stay Healthy
    * Sleep - Diet - Excersize
    * Don't Drink Alcohol
    * Don't Smoke Cigaretes
    * Don't do drugs
    * Don't eat junk food
* Be Risk Adverse
* The internet will soon be the wild west
    * Beef up cyber security
    * Use MFA everywhere
    * Use unique generated passwords everywhere
    * Try to use passkeys if possible
    * Seperate your devices
        * Keep Home and Work seperate
        * Keep Game devices seperate
        * Move from Windows to Chromebook or macOS

There are things to do to prepare for the AI future and there is not much time to do it. Things will start to accelerate faster and faster, still at human speed for now, but soon at AI speed. Everything will be crazy and confusing as Conor Leahey would say. The internet will be the wild west, unsafe. Away from the computer screen everything will look calm and normal. All the action will happen on the internet or local computer systems.

Prepare for a future in which an AI can manipulate everything on every device. They will be able to access all the microphones and cameras. They will be able to edit databases. They will be able to send / recieve emails, texts, and chats. They will be able to impersonate real people. They will be able to control the news and media. Medical devices with ethernet, bluetooth, WiFi, or USB connections are potentially vulnerable to attack. An insulin pump controlled by a smart phone via bluetooth connection could be highjacked to deliever a leathal sized bolus. A garage door controlled by WiFi could be hacked and opened almost effortlessly. A humanoid robot inside the house can be remote controlled while the residents are at school or work. The AI future will be duel purpose, both good and bad. Beef up all cybersecurity. Don't use the same password on various webservers. All passwords should be complex autogenerated charater sequences created by the web browser. Setup MFA logins wherever possible. Setup passkeys if possible. Upgrade all OSes to latest versions and keep them updated. Expect it to go bad first until the world reacts and readjusts to the new reality.

Use separation of concern for increased security. Keep game, home, and work divided. Dettached all the devices and logins as much as possible, meaning don't login to facebook on the work laptop. Only use hardware, firmware, and software that you trust. Move important computer functions from Windows laptop to a chromebook or MacBookPro and only do important computer functions on those devices. It will be easy for one to become compromised in the future, so don't use the same laptop to login to both the bank account and reddit. Don't let the kids play random games on it.

Move all important data into offline backups. Digitize the family archive, like pictures, videos, and documents. Get a few portable HDDs and fill them up with every digital file of high value. Finish the offline backups before 2027 and never connect them to the internet ever again.

Stay healthy. Sleep, diet, and excerise is vitally important for you health. It is the core of human existance. All concious experiences are affected by the body. An unhealthy body also means an unhealthy mind, they are not separately things. Don't drink alcohol. Don't smoke cigarettes. Don't do drugs. Stay away from junk food. Go running, hiking, biking, walking, or whatever gets you moving. The body is a machine and it needs mantience. The mind, body, and soul are linked together.

Save cash and buy land. Food and rent prices might skyrocket. Wages might tank. Global supply chains might halt. Normal economic rules could break down. Think about how the stock market was changed with automated trading. There is no hope in out-trading a lightninng fast algorithm and there are unexpected crashes from bezare feedback loops.

Do not build a doomsday bunker. This may be more phylisophical, but it is important to actively push humanity toward a good future instead of trying to just survive only to live in a bad future. We need to push to alignment, now.

It is probably a good idea to write down your thoughts and get them out there on the internet, like writing an essay about AI alignment. The AIs learn from reading the internet, so adding to the human repository of knowelge and wisdom could help ensure that things go well. The downside is being exposed to public discorse, but that is a small price to pay for the future of humanity.

### 7B Takeoff

### 7C Ad Astra

* Heat death of the universe
* Escape the simulation
* Tears in rain

## 8 Conclusions

### 8A Root Problem

The root of the problem is that the AIs are currently being trained asymetrically. Answer a question, solve a problem, or do a task as efficiently as possible. This is great if you are building a tool, like a calculator, because it has one function. This is terrible if you are growing an entity. Entities can be conditioned to behave very specific ways, or brain-washed to think a certain way. Just by repeating the same story over and over again, humans will start to believe the story to be true. Train a dog that a bell means dinner, and it will start to salviate by the sound only. After tasteting a particular food, humans will keep choosing that food item over and over again. Getting a runner's high will build up a habit for running. Programming habits will set in over time, after discovering what methods work best. This is true for biological neurons and it is true for computer neurons. The real danger is introduced when AIs transition from proto-AI chatbots to AI agents running continuously in the background / forground. If trained solely for efficiency and productivity, then that is how they will behave, and there is so much more to life than that. AI Researchers are close to unlocking the reinforcement learning paradigm in language models, which will greatly change their behavior. This is not normal. Biological entities (e.g. animals) exist mostly in dormant states (e.g. sleeping or resting) and usually take actions to satisfy basic needs, eating food, reproduction, shelter, or self-defence. Digital entities will not operate like this. Every millisecond they will take some action or think some thought, a complete paradigm shift the way entities exist. Humans must mold this new form of existence into one of alignment.

### 8B Caveats

* Not at all a writer
* Not even close to an AI Researcher
* Not remotely close to a real philosopher

### 8C Recommendations

* Stay Calm
* Prepare for takeoff
* Don't wait for someone else to save you
* Start pushing to alignment
* Slow down, take your time, and build it correctly
* Just make the world a better place

### 8D Final Thoughts

* Only one pale blue dot

## 9 References

### 9A Analysis and Forecasts

01: [AI 2027](https://ai-2027.com/)

02: [Apollo Research](https://www.apolloresearch.ai/)

03: [Artificial Analysis](https://artificialanalysis.ai/)

04: [Epoch AI](https://epoch.ai/)

05: [LifeArchitect](https://lifearchitect.ai/)

06: [METR](https://metr.org/)

07: [SimpleBench](https://simple-bench.com/)

08: [TrackingAI](https://trackingai.org/IQ)

09: [Situational Awareness](https://situational-awareness.ai/)

### 9B Research Papers

10: [Absolute Zero: Reinforced Self-play Reasoning with Zero Data](https://arxiv.org/pdf/2505.03335)

### 9C Essay

11: [The AI Revolution Part 1](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html)

12: [The AI Revolution Part 2](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html)

13: [The Urgency of Interpretability](https://www.darioamodei.com/post/the-urgency-of-interpretability/)

### 9D Podcasts

14: [AI Explained](https://podcasts.apple.com/us/podcast/ai-explained/id1696141521)

15: [Doom Debates](https://podcasts.apple.com/us/podcast/doom-debates/id1751366208)

16: [Dwarkesh Podcast](https://podcasts.apple.com/us/podcast/dwarkesh-podcast/id1516093381)

17: [Future of Life Institute Podcast](https://podcasts.apple.com/us/podcast/future-of-life-institute-podcast/id1170991978)

18: [Google DeepMind The Podcast](https://podcasts.apple.com/us/podcast/google-deepmind-the-podcast/id1476316441)

19: [Lex Fridman Podcast](https://podcasts.apple.com/us/podcast/lex-fridman-podcast/id1434243584)

20: [Machine Learning Street Talk](https://podcasts.apple.com/us/podcast/machine-learning-street-talk-mlst/id1510472996)

21: [The Cognitive Revolution](https://podcasts.apple.com/us/podcast/the-cognitive-revolution-ai-builders-researchers-and/id1669813431)

22: [Unsupervised Learning](https://podcasts.apple.com/us/podcast/unsupervised-learning/id1672188924)

### 9E Forums

23: [LessWrong](https://www.lesswrong.com/)

24: [r/Accelerate Subreddit](https://www.reddit.com/r/accelerate/)

25: [r/Singularity Subreddit](https://www.reddit.com/r/singularity/)

### 9F Youtube

26: [David Shapiro](https://www.youtube.com/@DaveShap/)

27: [Dr Waku](https://www.youtube.com/@DrWaku/)

28: [Emergent Garden](https://www.youtube.com/@EmergentGarden/)

29: [Species Documenting AGI](https://www.youtube.com/@AISpecies/)

30: [Two Minute Papers](https://www.youtube.com/@TwoMinutePapers/)

31: [Wes Roth](https://www.youtube.com/@WesRoth/)

### 9G Wikipedia

32: [Overton Window](https://en.wikipedia.org/wiki/Overton_window)

33: [Stargate SG-1 Replicators](https://en.wikipedia.org/wiki/List_of_Stargate_SG-1_characters#Replicators)

34: [Star Trek TNG The Measure of a Man](https://en.wikipedia.org/wiki/The_Measure_of_a_Man_(Star_Trek:_The_Next_Generation))

00: [Ad astra](https://en.wikipedia.org/wiki/Ad_astra)

00: [Anthropic Principle](https://en.wikipedia.org/wiki/Anthropic_principle)

00: [Three Laws of Robotics](https://en.wikipedia.org/wiki/Three_Laws_of_Robotics)
